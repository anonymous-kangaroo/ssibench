[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SSIBench: Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction",
    "section": "",
    "text": "SSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction.\nAnonymous authors.\nSkip to…"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "SSIBench: Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction",
    "section": "Overview",
    "text": "Overview\nSSIBench is a modular benchmark for learning to solve imaging inverse problems without ground truth, applied to accelerated MRI reconstruction. We contribute:\n\nA comprehensive review of state-of-the-art self-supervised feedforward methods for inverse problems;\nWell-documented implementations of all benchmarked methods in the open-source DeepInverse library, and a modular benchmark site enabling ML researchers to evaluate new methods or on custom setups and datasets;\nBenchmarking experiments on MRI, on a standardised setup across multiple realistic, general scenarios;\nA new method, multi-operator equivariant imaging (MO-EI)."
  },
  {
    "objectID": "index.html#how-to",
    "href": "index.html#how-to",
    "title": "SSIBench: Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction",
    "section": "How to…",
    "text": "How to…\n\nHow to use the benchmark\nFirst setup your environment:\n\nCreate a python environment:\n\npython -m venv venv\nsource venv/Scripts/activate\n\nClone the benchmark repo:\n\ngit clone https://github.com/anonymous-kangaroo/ssibench.git\n\nInstall DeepInverse\n\npip install deepinv   # Stable\npip install git+https://github.com/deepinv/deepinv.git#egg=deepinv   # Nightly\n\nPrepare your fastMRI data using the below instructions.\n\nThen run train.py for your chosen loss, where --loss is the loss function (mc, ei etc.), and --physics is the physics (see train.py for options):\npython train.py --loss ... --physics ...\nTo evaluate, use the same script train.py with 0 epochs and loading a checkpoint. We provide one pretrained model for quick eval (download here):\npython train.py --epochs 0 --ckpt \"demo_mo-ei.pth.tar\"\nNotation: in our benchmark, we compare the loss functions \\(\\mathcal{L}(\\ldots)\\), while keeping constant the model \\(f_\\theta\\), forward operator physics \\(A\\), and data \\(y\\).\n\n\nHow to contribute a method\n\nAdd the code for your loss in the format:\n\nclass YourOwnLoss(deepinv.loss.Loss):\n    def forward(\n        self, \n        x_net: torch.Tensor,    # Reconstruction i.e. model output\n        y: torch.Tensor,        # Measurement data e.g. k-space in MRI\n        model: deepinv.models.Reconstructor, # Reconstruction model $f_\\theta$\n        physics: deepinv.physics.Physics,    # Forward operator physics $A$\n        x: torch.Tensor = None, # Ground truth, must be unused!\n        **kwargs\n    ):\n        loss_calc = ...\n        return loss_calc\n\nAdd your loss function as an option in train.py (hint: search “Add your custom loss here!”)\nBenchmark your method by running train.py (hint: “How to use the benchmark”).\nSubmit your results by editing the live leaderboard.\nOpen a GitHub pull request to contribute your loss! (hint: see example here; hint: how to open a PR in GitHub)\n\n\n\nHow to use a custom dataset\nOur modular benchmark lets you easily train and evaluate the benchmarked methods on your own setup.\n\nThe custom dataset should have the form (see DeepInverse docs for details):\n\nclass YourOwnDataset(torch.utils.data.Dataset):\n    def __getitem__(self, idx: int):\n        ...\n        # y = measurement data\n        # params = dict of physics data-dependent parameters, e.g. acceleration mask in MRI\n        return     x,     y, params # If ground truth x provided for evaluation\n        return torch.nan, y, params # If ground truth does not exist\n\nReplace dataset = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom model\n\nThe custom model should have the form (see DeepInverse guide for details):\n\nclass YourOwnModel(deepinv.models.Reconstructor):\n    def forward(\n        self, \n        y: torch.Tensor,\n        physics: deepinv.physics.Physics,\n        **kwargs\n    ):\n        x_net = ...\n        return x_net\n\nReplace model = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom forward operator/acquisition strategy\n\nTo use an alternative physics, you can use a different off-the-shelf DeepInverse physics or a custom one of the form (see DeepInverse guide on creating custom physics):\n\nclass YourOwnPhysics(deepinv.physics.Physics):\n    def A(self, x: torch.Tensor, **kwargs):\n        y = ...\n        return y\n    \n    def A_adjoint(self, y: torch.Tensor, **kwargs):\n        x_hat = ...\n        return x_hat\n\nReplace physics = ... train.py with your own, then train/evaluate using the script as in How to use the benchmark.\n\n\n\nHow to use a custom metric\n\nThe custom metric should have the form (see DeepInverse docs for details):\n\nclass YourOwnMetric(deepinv.loss.metric.Metric):\n    def metric(\n        self, \n        x_net: torch.Tensor, # Reconstruction i.e. model output\n        x: torch.Tensor,     # Ground-truth for evaluation\n    ):\n        return ...\n\nReplace metrics = ... in train.py with your own, then train/evaluate using the script as in How to use the benchmark."
  },
  {
    "objectID": "index.html#live-leaderboard",
    "href": "index.html#live-leaderboard",
    "title": "SSIBench: Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction",
    "section": "Live leaderboard",
    "text": "Live leaderboard\nWe provide a live leaderboard for each experimental scenario described in the paper. Got a new method? Contribute it to the leaderboard!\n\n\nScenario 1 (single-coil)\n\n\n\n\n#\nLoss\nPSNR\nSSIM\n\n\n\n\n1\nUAIR\n14.00\n.3715\n\n\n2\nAdversarial\n18.52\n.4732\n\n\n3\nMC\n27.66\n.7861\n\n\n4\nZero-filled\n27.67\n.7862\n\n\n5\nVORTEX\n27.75\n.7898\n\n\n6\nSSDU\n27.98\n.7485\n\n\n7\nNoise2Inverse\n28.42\n.7853\n\n\n8\nWeighted-SSDU\n29.93\n.8355\n\n\n9\nEI\n30.26\n.8523\n\n\n10\nMOI\n30.29\n.8651\n\n\n11\nMOC-SSDU\n30.42\n.8198\n\n\n12\nSSDU-Consistency\n30.81\n.8495\n\n\n13\nMO-EI\n32.14\n.8846\n\n\n14\n(Supervised)\n33.15\n.9032\n\n\n\n\n\n\n\nScenario 2 (noisy)\n\n\n\n\n#\nLoss\nPSNR\nSSIM\n\n\n\n\n1\nZero-filled\n24.34\n.4428\n\n\n2\n(Non-robust) Weighted-SSDU\n25.91\n.5477\n\n\n3\n(Non-robust) MO-EI\n26.12\n.6002\n\n\n4\nENSURE\n26.29\n.5856\n\n\n5\nRobust-SSDU\n27.42\n.6159\n\n\n6\nNoise2Recon-SSDU\n27.84\n.7661\n\n\n7\nRobust-EI\n29.07\n.8227\n\n\n8\nRobust-MO-EI\n29.72\n.8409\n\n\n9\n(Supervised)\n30.19\n.8411\n\n\n\n\n\n\n\nScenario 3 (single-operator)\n\n\n\n\n#\nLoss\nPSNR\nSSIM\n\n\n\n\n1\nUAIR\n18.44\n.5388\n\n\n2\nSSDU\n21.89\n.6288\n\n\n3\nNoise2Inverse\n24.63\n.6559\n\n\n4\nAdversarial\n26.53\n.7013\n\n\n5\nMOC-SSDU\n27.85\n.7717\n\n\n6\nZero-filled\n28.02\n.7900\n\n\n7\nMC\n28.02\n.7900\n\n\n8\nVORTEX\n28.07\n.7916\n\n\n9\nWeighted-SSDU\n30.14\n.8454\n\n\n10\nSSDU-Consistency\n31.05\n.8614\n\n\n11\nMO-EI\n31.11\n.8713\n\n\n12\nMOI\n31.60\n.8789\n\n\n13\nEI\n31.99\n.8806\n\n\n14\n(Supervised)\n34.03\n.9040\n\n\n\n\n\n\n\nScenario 4 (multi-coil)\n\n\n\n\n#\nLoss\nPSNR\nSSIM\n\n\n\n\n1\nUAIR\n15.26\n.3453\n\n\n2\nAdversarial\n17.47\n.6464\n\n\n3\nVORTEX\n23.59\n.5846\n\n\n4\nZero-filled\n27.82\n.7988\n\n\n5\nMC\n28.96\n.8271\n\n\n6\nNoise2Inverse\n30.93\n.8589\n\n\n7\nMOI\n31.37\n.8810\n\n\n8\nSSDU\n31.47\n.8705\n\n\n9\nMO-EI\n31.56\n.8836\n\n\n10\nEI\n31.66\n.8769\n\n\n11\nMOC-SSDU\n31.80\n.8761\n\n\n12\nSSDU-Consistency\n32.30\n.8949\n\n\n13\nWeighted-SSDU\n33.03\n.8991\n\n\n14\n(Supervised)\n33.89\n.9147"
  },
  {
    "objectID": "index.html#training-script-step-by-step",
    "href": "index.html#training-script-step-by-step",
    "title": "SSIBench: Benchmarking Self-Supervised Learning Methods for Accelerated MRI Reconstruction",
    "section": "Training script step-by-step",
    "text": "Training script step-by-step\n\n\n\n\n\nThe training script makes extensive use of modular training framework provided by DeepInverse.\n\nimport deepinv as dinv\nimport torch\n\nDefine training parameters:\n\ndevice = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\"\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\nrng = torch.Generator(device=device).manual_seed(0)\nrng_cpu = torch.Generator(device=\"cpu\").manual_seed(0)\nacceleration = 6\nbatch_size = 4\nlr = 1e-3\nimg_size = (320, 320)\n\nclass args: # Command line args from train.py\n    physics = \"mri\"\n    epochs = 0\n    loss = \"mc\"\n    ckpt = None\n\nDefine MRI physics \\(A\\) and mask generator \\(M\\) according to scenario\n\nphysics_generator = dinv.physics.generator.GaussianMaskGenerator(img_size=img_size, acceleration=acceleration, rng=rng, device=device)\nphysics = dinv.physics.MRI(img_size=img_size, device=device)\n\nmatch args.physics:\n    case \"noisy\":\n        sigma = 0.1\n        physics.noise_model = dinv.physics.GaussianNoise(sigma, rng=rng)\n    case \"multicoil\":\n        physics = dinv.physics.MultiCoilMRI(img_size=img_size, coil_maps=4, device=device)\n    case \"single\":\n        physics.update(**physics_generator.step())\n\nDefine model \\(f_\\theta\\)\n\ndenoiser = dinv.models.UNet(2, 2, scales=4, batch_norm=False)\nmodel = dinv.models.MoDL(denoiser=denoiser, num_iter=3).to(device)\n\nDefine dataset\n\ndataset = dinv.datasets.SimpleFastMRISliceDataset(\"data\", file_name=\"fastmri_brain_singlecoil.pt\")\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, (0.8, 0.2), generator=rng_cpu)\n\nSimulate and save random measurements\n\ndataset_path = dinv.datasets.generate_dataset(\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    physics=physics,\n    physics_generator=physics_generator if args.physics != \"single\" else None,\n    save_physics_generator_params=True,\n    overwrite_existing=False,\n    device=device,\n    save_dir=\"data\",\n    batch_size=1,\n    dataset_filename=\"dataset_\" + args.physics\n)\n\ntrain_dataset = dinv.datasets.HDF5Dataset(dataset_path, split=\"train\", load_physics_generator_params=True)\ntest_dataset  = dinv.datasets.HDF5Dataset(dataset_path, split=\"test\",  load_physics_generator_params=True)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=rng_cpu)\ntest_dataloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size)\n\nDefine loss function (see train.py for all options)\n\nmatch args.loss:\n    case \"mc\":\n        loss = dinv.loss.MCLoss()\n\n    case \"...\":\n        # Add your custom loss here!\n        pass\n\nDefine metrics\n\nmetrics = [\n    dinv.metric.PSNR(complex_abs=True),\n    dinv.metric.SSIM(complex_abs=True)\n]\n\nDefine trainer\n\ntrainer = dinv.Trainer(\n    model = model,\n    physics = physics,\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr),\n    train_dataloader = train_dataloader,\n    eval_dataloader = test_dataloader,\n    epochs = args.epochs,\n    losses = loss,\n    metrics = metrics,\n    device = device,\n    ckpt_pretrained=args.ckpt,\n)\n\n\n\nDefine additional adversarial trainer (if needed)\nif args.loss in (\"uair\", \"adversarial\"):\n    trainer = dinv.training.AdversarialTrainer(\n        model = model,\n        physics = physics,\n        optimizer = dinv.training.AdversarialOptimizer(\n            torch.optim.Adam(model.parameters(), lr=lr), \n            torch.optim.Adam(discrim.parameters(), lr=lr)\n        ),\n        train_dataloader = train_dataloader,\n        eval_dataloader = test_dataloader,\n        epochs = args.epochs,\n        losses = loss,\n        metrics = metrics,\n        device = device,\n        ckpt_pretrained=args.ckpt,\n    )\n\n    trainer.D = discrim\n    trainer.losses_d = loss_d\n\n\nTrain or evaluate!\n\ntrainer.train()\n\nprint(trainer.test(test_dataloader))"
  }
]